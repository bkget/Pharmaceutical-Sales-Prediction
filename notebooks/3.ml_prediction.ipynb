{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 7)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "from file_handler import FileHandler\n",
    "from log import get_logger\n",
    "from plots import Plots\n",
    "\n",
    "file_handler = FileHandler()\n",
    "my_logger = get_logger(\"Prediction\") \n",
    "plot = Plots()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 06:02:42,178 — FileHandler — DEBUG — file read as csv\n",
      "2022-05-28 06:02:42,309 — FileHandler — DEBUG — file read as csv\n"
     ]
    }
   ],
   "source": [
    "train_data = file_handler.read_csv(\"../data/cleaned_train.csv\")\n",
    "test_data = file_handler.read_csv(\"../data/cleaned_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encode Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 06:02:42,884 — Prediction — DEBUG — Date is encoded successfully.\n",
      "2022-05-28 06:02:42,884 — Prediction — DEBUG — Date is encoded successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Train with only by the opened stores and Sales greater than zero.\n",
    "    \n",
    "    train_data = train_data[train_data['Open'] == 1]\n",
    "    train_data = train_data[train_data['Sales'] > 0.0]\n",
    "\n",
    "    # Label encode Date in both training and testing datasets\n",
    "    for dataset in (train_data, test_data):\n",
    "        encoder = preprocessing.LabelEncoder()\n",
    "        dataset['Date'] = encoder.fit_transform(dataset['Date'])\n",
    "\n",
    "    my_logger.debug('Date is encoded successfully.')\n",
    "            \n",
    "except Exception as e:\n",
    "    my_logger.exception(f'Exception occured in Date encoding!, {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 06:02:46,424 — Prediction — DEBUG — Data is Normalized successfully.\n",
      "2022-05-28 06:02:46,424 — Prediction — DEBUG — Data is Normalized successfully.\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "trainining_columns = ['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'StoreType',\\\n",
    "                    'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2',\\\n",
    "                    'Promo2SinceWeek','Promo2SinceYear', 'PromoInterval', 'Day', 'Month', 'Year', 'DayOfYear', 'WeekOfYear']\n",
    "\n",
    "testing_columns = ['Store', 'DayOfWeek', 'Date', 'Open', 'Promo', 'StateHoliday','SchoolHoliday', 'StoreType', 'Assortment',\\\n",
    "                  'CompetitionDistance','CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', \\\n",
    "                  'Promo2SinceYear', 'PromoInterval', 'Day', 'Month', 'Year', 'DayOfYear', 'WeekOfYear']\n",
    "\n",
    "temp_train_data = train_data.copy()\n",
    "temp_test_data = test_data.copy()   \n",
    "\n",
    "try:\n",
    "    for i in trainining_columns:\n",
    "    \n",
    "        # fit on training data column\n",
    "        scale = scaler.fit(temp_train_data[[i]])\n",
    "        \n",
    "        # transform the training data column\n",
    "        temp_train_data[i] = scale.transform(temp_train_data[[i]])\n",
    "    \n",
    "    for i in testing_columns:\n",
    "    \n",
    "        # fit on training data column\n",
    "        scale = scaler.fit(temp_test_data[[i]])\n",
    "        \n",
    "        # transform the training data column\n",
    "        temp_test_data[i] = scale.transform(temp_test_data[[i]]) \n",
    "    \n",
    "    my_logger.debug('Data is Normalized successfully.')\n",
    "    \n",
    "except Exception as e:\n",
    "    my_logger.debug(f\"Exception occured while Normalizing the dataset, {e}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f08ea943be090a14eff5269cda570ac55dcc0e2bd93317a14b7d7e20047a087"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
